{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3               4\n",
       "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
       "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
       "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
       "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
       "149  5.9  3.0  5.1  1.8  Iris-virginica"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/'\n",
    "        'machine-learning-databases/iris/iris.data', header=None)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAESCAYAAAAbq2nJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11959b278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# select setosa and versicolor\n",
    "y = df.iloc[0:100, 4].values\n",
    "# After taking the variables, codify the predicted variable\n",
    "y = np.where(y == 'Iris-setosa', -1, 1)\n",
    "\n",
    "# extract sepal length and petal length\n",
    "X = df.iloc[0:100, [0, 2]].values\n",
    "\n",
    "# plot data\n",
    "sns.regplot(X[:50, 0], X[:50, 1],\n",
    "            color='red', label='setosa', marker = \"+\", fit_reg = False)\n",
    "sns.regplot(X[50:100, 0], X[50:100, 1],\n",
    "            color='blue', label='versicolor', fit_reg = False)\n",
    "\n",
    "plt.xlabel('sepal length [cm]')\n",
    "plt.ylabel('petal length [cm]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "#plt.savefig('./images/02_06.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response and predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [2, 3]]\n",
    "y = iris.target\n",
    "\n",
    "print('Class labels:', np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Split and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=21)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "# Same transformation for both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=0.1, fit_intercept=True,\n",
       "      n_iter=40, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
       "      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "ppn = Perceptron(n_iter=40, eta0=0.1, random_state=0)\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 4\n"
     ]
    }
   ],
   "source": [
    "y_pred = ppn.predict(X_test_std)\n",
    "# Result np.array\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=1000.0, random_state=0)\n",
    "lr.fit(X_train_std, y_train)\n",
    "y_pred = lr.predict(X_test_std)\n",
    "print('Accuracy: %.4f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: in scikit-learn, the regularization parameter for the logistic regression is C, the inverse of lambda. That is:\n",
    "$C = \\frac{1}{\\lambda} $ Thus, as C decreases, we are increasing the regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.28261729e-04,   9.99871734e-01,   3.85231188e-09],\n",
       "       [  8.07251699e-01,   1.92748301e-01,   1.08981637e-30],\n",
       "       [  8.10628071e-01,   1.89371929e-01,   2.53347517e-35],\n",
       "       [  8.51602078e-01,   1.48397922e-01,   1.19662325e-32],\n",
       "       [  4.99333149e-05,   9.99950033e-01,   3.34145807e-08],\n",
       "       [  4.06375383e-06,   9.99832625e-01,   1.63311682e-04],\n",
       "       [  7.86994992e-01,   2.13005008e-01,   2.40830985e-34],\n",
       "       [  7.13064322e-10,   1.92536146e-01,   8.07463853e-01],\n",
       "       [  8.41105426e-01,   1.58894574e-01,   3.69908161e-32],\n",
       "       [  8.31741996e-01,   1.68258004e-01,   5.51128587e-34]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict_proba(X_test_std[0:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: in scikit-learn, the regularization parameter for the SVM is C, the inverse of lambda. That is:\n",
    "$C = \\frac{1}{\\lambda} $ Thus, as C decreases, we are increasing the regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=0)\n",
    "svm.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test_std)\n",
    "print('Accuracy: %.4f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using RBF-kernel, the $\\gamma$ parameter is the inverse of the standardizing parameter: $\\gamma = \\frac{1}{2\\sigma^2}$ . Thus, the higher the gamma, the lower the standardizing and the more similar will all the observations appear. Thus, the higher the gamma, the lower our regularization level. Thus, both regularizing terms in SVM are the strongest when they have low values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='rbf', random_state=0, gamma=0.2, C=1.0)\n",
    "svm.fit(X_train_std, y_train)\n",
    "y_pred = svm.predict(X_test_std)\n",
    "print('Accuracy: %.4f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we secularly increase both C and gamma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8667\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='rbf', random_state=0, gamma=100.0, C=1.0)\n",
    "# Let the C be, but secularly increase gamma and thus decrease the regularization.\n",
    "svm.fit(X_train_std, y_train)\n",
    "y_pred = svm.predict(X_test_std)\n",
    "print('Accuracy: %.4f' % accuracy_score(y_test, y_pred))\n",
    "# Our prediction suffers, due to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a Decision TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test_std)\n",
    "print('Accuracy: %.4f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Random Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefit: not that many hyperparameters to tune. Just number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(criterion='entropy',\n",
    "                                n_estimators=5000, \n",
    "                                random_state=1,\n",
    "                                n_jobs=2)\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(X_test_std)\n",
    "print('Accuracy: %.4f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "knn.fit(X_train_std, y_train)\n",
    "y_pred = knn.predict(X_test_std)\n",
    "print('Accuracy: %.4f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
